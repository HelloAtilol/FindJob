- **深度学习的优化函数**
	1. **批梯度下降(BGD)**

	    更新规则：每次更新参数时使用全部训练样本；
	    $$ \theta = \theta- \eta\frac{\partial J(\theta)}{\partial\theta}$$
	    优点：理想状态下经过足够多的迭代后可以达到全局最优。（对于凸函数可以收敛到全局极小值，对于非凸函数可以收敛到局部最小值）
	    缺点：一次更新就要对整个数据集计算梯度，所以计算非常慢。
	
	2. **随机梯度下降(SGD)**
	    优化方式：每次更新参数时随机选用一个样本。
	    $$ \theta = \theta- \eta\frac{\partial J(\theta;x^{(i)};y^{(i)})}{\partial\theta} $$
	    优点：相比于BGD，训练速度更快，更快收敛。
	    缺点：随机梯度下降会带来一定的问题，因为计算得到的并不是准确的一个梯度，SGD 的噪音较 BGD 要多，使得 SGD 并不是每次迭代都向着整体最优化方向。 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近。SGD 因为更新比较频繁，会造成 cost function 有严重的震荡。BGD 可以收敛到局部极小值，当然 SGD 的震荡可能会跳到更好的局部极小值处。当我们稍微减小 learning rate，SGD 和 BGD 的收敛性是一样的。
	    
	3. **小批次梯度下降(MBGD)**   
	    优化方式：每次更新参数时利用一小批样本。
	    $$ \theta = \theta- \eta\frac{\partial J(\theta;x^{(i;i+n)};y^{(i;i+n)})}{\partial\theta} $$
	    优点：相较于BGD更快，相较于SGD更稳定
	    缺点：当我们采用小的学习率的时候，会导致网络在训练的时候收敛太慢；当我们采用大的学习率的时候，会导致在训练过程中优化的幅度跳过函数的范围，也就是可能跳过最优点。对于非凸函数，还要避免陷于局部极小值处，或者鞍点处。
	    
	4. **Momentum**
	    优化方式：在梯度下降的方向上计算一个指数加权平均，利用这个来代替权重更新。俗一点的理解就是“如果梯度下降显示，我们在一直朝着某一个方向在下降的话，我让这个方向的的学习速率快一点，如果梯度下降在某一个方向上一直是摆来摆去的，那么就让这个方向的学习速率慢一点”。
	    $$ v_t=\lambda v_{t-1}+\eta\frac{\partial J(\theta)}{\partial\theta} $$
	    $$ \theta = \theta-v_t $$
	    优点：加速了横轴下降的速度，并减缓了纵轴的摆动频率。
	    
	5. **AdaGrad**
	    优化方式：根据自变量在每个维度的梯度值的大小来调整各位维度上的学习率，从而避免统一的学习率难以适应所有维度的问题。
	    $$g_{t,i}=\frac{\partial J(\theta_{t,i})}{\partial\theta}$$
	    $$ \theta_{t+1,i}=\theta_{t,i}-\frac{\eta}{\sqrt{G_{t,i}+\varepsilon}}g_{t,i} $$
	    其中G是一个对角矩阵，对角线元素是截止到当前时刻的历史梯度的平方和。
	    优点：适合于特征稀疏的场景。不需要手动设置学习率。
	    缺点：其分母梯度平方的累加和。因为每次加入的都是一个正数，随着训练的进行，学习率将会变得无限小，此时算法将不能进行参数的迭代更新

	6. **RMSProp**
	    优化方式：RMSProp 基于 AdaGrad，进行了一些小小的改动，也解决了我们上面提出来的，在随着训练时间增长，AdaGrad 的步伐会变得很小的问题。RMSProp 在计算 grad_squared 的时候，加上了一个 decay （衰减率）的东西，这样造成的效果即是，既保留了 AdaGrad 的特性，又不会一直过分增加 grad_squared 导致最后阻力过大。
	    $$ E[g^2] _t=0.9E[g^2]_{t-1}+0.1g_t^2$$
	    $$ \theta_{t+1}=\theta_t-\frac{\eta}{\sqrt{E[g^2]_t+\varepsilon}}g_t $$
	    
	7. **Adam(Adaptive Moment Estimation)**
	    Adam相当于RMSProp+Momentum，即存储了过去梯度的平方的指数衰减平均值,也保存了过去梯度的指数衰减平均值,通过校正的一阶矩(均值)和二阶矩(方差)估计来抵消误差。
	    $$ m_t=\beta_1m_{t-1}+(1-\beta_1)g_t $$
	    $$ v_t=\beta_2v_{t-1}+(1-\beta_1)g_t^2 $$
	    $$ \hat{m}_t=\frac{m_t}{1-\beta_1^t} $$
	    $$ \hat{v}_t=\frac{v_t}{1-\beta_2^t} $$
	    $$ \theta_{t+1}=\theta_t-\frac{\eta}{\sqrt{\hat{v}_t}+\varepsilon}\hat{m}_t $$
	    实践证明,Adam相比于其他适应性学习方法效果要好.
	    建议$\beta_1=0.9,\beta_2=0.999,\varepsilon=10e-8$

---

- **深度学习的损失函数**

	**分类**
	1.  Sigmoid_cross_entropy
	    测量每个类别独立且不互相排斥的离散分类人中的概率，可以执行多标签分类。
	    $$ L(y,\hat{y}) = -\frac{1}{2}*(\hat{y}*log(sigmoid(y))+(1-\hat{y})*log(1-sigmoid(y)))  $$
	    
	    ```python
	    # keras 的接口：
	    binary_crossentropy(y_true,y_pred)
	    ```
	    
	    > 对于softmax_cross_entropy, sigmoid_cross_entropy之间的区别：
	    > softmax_cross_entropy是多分类问题，有多个类别，且互斥；激活函数使用softmax，keras的损失函数使用`categorical cross-entropy`
	    > sigmoid_cross_entropy是多目标分类问题，有多个类别，但类别之间互相独立，可以转换成多个二分类问题解决。激活函数使用sigmoid，keras的损失函数使用`binary cross-entropy`
	    
	2. balanced_sigmoid_cross_entropy
	    相较于sigmoid_cross_entropy的优势在于加入平衡参数，可以进行正负样本的平衡。
	    $$ L(y,\hat{y}) = -\frac{1}{2}*(\beta\hat{y}*log(sigmoid(y))+(1-\beta)(1-\hat{y})*log(1-sigmoid(y))) $$
	    ```python
	    # keras 接口：
	    categorical_crossentropy(y_true, y_pred)
      ```
	
	3. Focal Loss
	    通过不同类别的分类概率$p_t$，概率越大，权重越小，也就实现了对easy example的权重进行抑制；
	    $$FL(p_t)=-\alpha_t(1-p_t)^\gamma log(p_t)$$
      当时反例时，使用$1-\alpha$代替$\alpha$
      ```python
        def focal_loss(logits, labels, gamma):
        '''
        :param logits:  [batch_size, n_class]
        :param labels: [batch_size]
        :return: -(1-y)^r * log(y)
        '''
        	softmax = tf.reshape(tf.nn.softmax(logits), [-1])  # [batch_size * n_class]
        	labels = tf.range(0, logits.shape[0]) * logits.shape[1] + labels
        	prob = tf.gather(softmax, labels)
        	weight = tf.pow(tf.subtract(1., prob), gamma)
	      	loss = -tf.reduce_mean(tf.multiply(weight, tf.log(prob)))
	      	return loss  
	    ```
	
	4. hinge_loss
	    也叫铰链损失，是SVM中的损失函数。合页损失优化到满足小于一定gap距离就会停止优化，所以，通常情况下，交叉熵损失效果优于合页损失。
	    $$ L(y,\hat{y}=\frac{1}{n}\sum_{i=1}{n}max(0,1-\hat{y}*y_i)) $$
	

**回归**

	1. MSE(均方误差)

 	2. MAE(平均绝对误差)
 	3. MAPE(平均绝对百分比误差)
 	4. MSLE(均方对数误差)
---
- **深度学习的激活函数**
	1.Sigmoid
	2.tanh
	3.Relu
	4.Leaky ReLU
	5.RReLU
	6.ELU
	7.Maxout

