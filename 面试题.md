- **深度学习的优化函数**
1. **批梯度下降(BGD)**
更新规则：每次更新参数时使用全部训练样本；
优点：理想状态下经过足够多的迭代后可以达到全局最优。（对于凸函数可以收敛到全局极小值，对于非凸函数可以收敛到局部最小值）
缺点：一次更新就要对整个数据集计算梯度，所以计算非常慢。
$$
\theta = \theta- \eta\frac{\partial J(\theta)}{\partial\theta}
$$

2. **随机梯度下降(SGD)**
优化方式：每次更新参数时随机选用一个样本。
优点：相比于BGD，训练速度更快，更快收敛。
缺点：随机梯度下降会带来一定的问题，因为计算得到的并不是准确的一个梯度，SGD 的噪音较 BGD 要多，使得 SGD 并不是每次迭代都向着整体最优化方向。 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近。SGD 因为更新比较频繁，会造成 cost function 有严重的震荡。BGD 可以收敛到局部极小值，当然 SGD 的震荡可能会跳到更好的局部极小值处。当我们稍微减小 learning rate，SGD 和 BGD 的收敛性是一样的。
$$
\theta = \theta- \eta\frac{\partial J(\theta;x^{(i)};y^{(i)})}{\partial\theta} 
$$

3. **小批次梯度下降(MBGD)**   
优化方式：每次更新参数时利用一小批样本。
优点：相较于BGD更快，相较于SGD更稳定
缺点：当我们采用小的学习率的时候，会导致网络在训练的时候收敛太慢；当我们采用大的学习率的时候，会导致在训练过程中优化的幅度跳过函数的范围，也就是可能跳过最优点。对于非凸函数，还要避免陷于局部极小值处，或者鞍点处。
$$
\theta = \theta- \eta\frac{\partial J(\theta;x^{(i;i+n)};y^{(i;i+n)})}{\partial\theta}
$$

4. **Momentum**
优化方式：在梯度下降的方向上计算一个指数加权平均，利用这个来代替权重更新。俗一点的理解就是“如果梯度下降显示，我们在一直朝着某一个方向在下降的话，我让这个方向的的学习速率快一点，如果梯度下降在某一个方向上一直是摆来摆去的，那么就让这个方向的学习速率慢一点”。
$$
v_t=\lambda v_{t-1}+\eta\frac{\partial J(\theta)}{\partial\theta}
$$
$$
\theta = \theta-v_t
$$

5. **AdaGrad**
优化方式：根据自变量在每个维度的梯度值的大小来调整各位维度上的学习率，从而避免统一的学习率难以适应所有维度的问题。
其中G是一个对角矩阵，对角线元素是截止到当前时刻的历史梯度的平方和。
优点：适合于特征稀疏的场景。不需要手动设置学习率。
缺点：其分母梯度平方的累加和。因为每次加入的都是一个正数，随着训练的进行，学习率将会变得无限小，此时算法将不能进行参数的迭代更新
$$
g_{t,i}=\frac{\partial J(\theta_{t,i})}{\partial\theta} \\
\theta_{t+1,i}=\theta_{t,i}-\frac{\eta}{\sqrt{G_{t,i}+\varepsilon}}g_{t,i}
$$

6. **RMSProp**
优化方式：RMSProp 基于 AdaGrad，进行了一些小小的改动，也解决了我们上面提出来的，在随着训练时间增长，AdaGrad 的步伐会变得很小的问题。RMSProp 在计算 grad_squared 的时候，加上了一个 decay （衰减率）的东西，这样造成的效果即是，既保留了 AdaGrad 的特性，又不会一直过分增加 grad_squared 导致最后阻力过大。
$$
E[g^2] _t=0.9E[g^2]_{t-1}+0.1g_t^2 \\
\theta_{t+1}=\theta_t-\frac{\eta}{\sqrt{E[g^2]_t+\varepsilon}}g_t 
$$

7. **Adam(Adaptive Moment Estimation)**
Adam相当于RMSProp+Momentum，即存储了过去梯度的平方的指数衰减平均值,也保存了过去梯度的指数衰减平均值,通过校正的一阶矩(均值)和二阶矩(方差)估计来抵消误差。
$$
m_t=\beta_1m_{t-1}+(1-\beta_1)g_t \\
v_t=\beta_2v_{t-1}+(1-\beta_1)g_t^2 \\
\hat{m}_t=\frac{m_t}{1-\beta_1^t} \\
\hat{v}_t=\frac{v_t}{1-\beta_2^t} \\
\theta_{t+1}=\theta_t-\frac{\eta}{\sqrt{\hat{v}_t}+\varepsilon}\hat{m}_t 
$$
实践证明,Adam相比于其他适应性学习方法效果要好.
建议$\beta_1=0.9,\beta_2=0.999,\varepsilon=10e-8$

---

- **常用损失函数**

1. 感知机损失
单层感知机的损失函数，也是0-1损失：
$$
L(w,b)=\sum_{i\in M}y_i(w*x_i+b)
$$
对应的参数更新：
$$
\hat w\leftarrow w-\eta x_iy_i \\
\hat b \leftarrow b-\eta y_i
$$

2. MSE均方误差
最常见的损失函数，也是线性回归的损失函数。
$$
L(w,b)=\frac{1}{n}\sum_{i=1}^{N}(\hat y_i-y_i)^2
$$
如果是线性回归，对w求导，那么参数更新：
$$
f(x_i) = wx+b \\
J(\theta) = \sum_{i=1}^{N}(f(x_i)-y_i)x_i \\
\hat w \leftarrow w -\eta J(\theta) \\
\hat b \leftarrow b - \eta (f(x_i)-y_i)
$$

3. 概率损失与交叉熵
逻辑回归的损失函数和大部分神经网络的损失函数。详见极大似然估计与逻辑回归。
概率损失，形式就是二项分布：
$$
L(w, b) = \prod_{i=1}^{m}p^{y^i}(1-p)^{1-{y^i}} \\
p = h(x) = \frac{1}{1+e^{-(wx+b)}}
$$
因此，对于多分类，可以延申为：
$$
L(w, b) = \prod_{k=1}^{K}p_k^{n_k}
$$
其中，$k\in K$代表类别，$n_k$代表在所有样本中的数量。那么就有了将概率损失转换为交叉熵的方法，取对数，则交叉熵为：
$$
L(w, b) = \frac{1}{m}\sum_k^{K}n_k\log(p_k)=\sum_k^{K}q_k\log(p_k)
$$
其中，$m$代表样本数量，则$q_k$代表样本中，类别$k$的真实概率，而$p_k$则是模型预测类别为$k$的概率。
则梯度优化方向：
$$
J(\theta) = \sum_{i=1}^{N}(f(x_i)-y_i)x_i \\
\hat w \leftarrow w -\eta J(\theta) \\
\hat b \leftarrow b - \eta (f(x_i)-y_i)
$$

4. Hinge_loss 合页损失，支持向量机的损失函数
5. Focal Loss
通过不同类别的分类概率$p_t$，概率越大，权重越小，也就实现了对easy example的权重进行抑制；
$$
FL(p_t)=-\alpha_t(1-p_t)^\gamma log(p_t)
$$



2.  Sigmoid_cross_entropy
测量每个类别独立且不互相排斥的离散分类人中的概率，可以执行多标签分类。
$$
L(y,\hat{y}) = -\frac{1}{2}*(\hat{y}*log(sigmoid(y))+(1-\hat{y})*log(1-sigmoid(y)))  
$$

	    ```python
	    # keras 的接口：
	    binary_crossentropy(y_true,y_pred)
	    ```
	    > 对于softmax_cross_entropy, sigmoid_cross_entropy之间的区别：
	    > softmax_cross_entropy是多分类问题，有多个类别，且互斥；激活函数使用softmax，keras的损失函数使用`categorical cross-entropy`
	    > sigmoid_cross_entropy是多目标分类问题，有多个类别，但类别之间互相独立，可以转换成多个二分类问题解决。激活函数使用sigmoid，keras的损失函数使用`binary cross-entropy`
	    
	2. balanced_sigmoid_cross_entropy
	    相较于sigmoid_cross_entropy的优势在于加入平衡参数，可以进行正负样本的平衡。
	    $$
	    L(y,\hat{y}) = -\frac{1}{2}*(\beta\hat{y}*log(sigmoid(y))+(1-\beta)(1-\hat{y})*log(1-sigmoid(y))) 
	  $$
	
	3. Focal Loss
	  通过不同类别的分类概率$p_t$，概率越大，权重越小，也就实现了对easy example的权重进行抑制；
	  $$
	  FL(p_t)=-\alpha_t(1-p_t)^\gamma log(p_t)
	  $$
	  当时反例时，使用$1-\alpha$代替$\alpha$
	  ```python
	    def focal_loss(logits, labels, gamma):
	    '''
	    :param logits:  [batch_size, n_class]
	    :param labels: [batch_size]
	    :return: -(1-y)^r * log(y)
	    '''
	    	softmax = tf.reshape(tf.nn.softmax(logits), [-1])  # [batch_size * n_class]
	    	labels = tf.range(0, logits.shape[0]) * logits.shape[1] + labels
	      	prob = tf.gather(softmax, labels)
	      	weight = tf.pow(tf.subtract(1., prob), gamma)
	      	loss = -tf.reduce_mean(tf.multiply(weight, tf.log(prob)))
	      	return loss  
	    ```
	
	4. hinge_loss
	    也叫铰链损失，是SVM中的损失函数。合页损失优化到满足小于一定gap距离就会停止优化，所以，通常情况下，交叉熵损失效果优于合页损失。
	    $$
	  L(y,\hat{y}=\frac{1}{n}\sum_{i=1}{n}max(0,1-\hat{y}*y_i))
	  $$
	
	**回归**
	
	1. MSE(均方误差)
	
	 	2. MAE(平均绝对误差)
	 	3. MAPE(平均绝对百分比误差)
	 	4. MSLE(均方对数误差)

---
- **深度学习的激活函数**
	1.Sigmoid
	    公式：
	    $$ f(x)=\frac{1}{1+e^{-x}} $$
	    取值范围:[0;1]
	    ![sigmoid](img\sigmoid.png)
	    缺点：两端梯度消失;输出不是"零为中心"；指数计算复杂度高。
	2.tanh
	    公式：
	    $$tanh(x)=2sigmoid(2x)-1=\frac{1-e^{-2x}}{1+e^{-2x}}$$
	    取值范围:[-1;1]
- ![tanh](img\tanh.png)
	    缺点：两端梯度消失；指数计算复杂度高。
	3.ReLU
	    公式：
	    $$ ReLU(x)=max(0, x) $$
	    取值范围：>=0
	    ![ReLU](img\ReLU.png)
	    优点：解决了在x>0时的梯度消失问题；在SGD中能够快速收敛；线性关系，计算复杂度低；
	    缺点：不是"零为中心"；随着训练进行，可能出现神经元不可逆转的死亡；
	4.Leaky ReLU
	    公式：$ f(x)=\begin{cases}  x & x>=0 \\ \alpha x & x<0 \end{cases} $
	    优点：神经元不会死亡；也不会梯度消失；能够快速收敛；计算速度快；
	    缺点：$\alpha$需要先验知识。
	5.RReLU
	    Leaky ReLU的$\alpha$服从一个分布，会在训练中随机产生并进行修正，在测试环节计算平均值。
	6.ELU
	    公式：$f(x)=\begin{cases} x&x>0 \\ \alpha(e^x-1) & x<=0 \end{cases}$
	    ![img](https://img-blog.csdn.net/20160917160040231)
	    优点：ReLU的所有优点，不会死亡，输出均值接近于0；
	    缺点：指数运算，效率相对较低。
	7.Maxout
	    公式：$ f(x)= \max(w_1^Tx+b_1, w_2^Tx+b_2,...,w_k^Tx+b_k) $
	    优点：因为ReLU是Maxout的特殊化，所以有ReLU的所有优点，且不会死亡；
	    缺点：参数较多，原本一组参数，因为编成k组，导致参数变多。
---
- **LSTM**
	输入：$C_{t-1}, h_{t-1}, x_t$
	输出：$C_t, h_t$
	![LSTM](img\LSTM.jpg)
	遗忘门：$$ f_t =\sigma(W_f[h_{t-1}, x_t]+b_f) $$
	输入门：$$ i_t =\sigma(W_i[h_{t-1}, x_t]+b_i) $$
	输出门：$$ o_t = \sigma(W_o[h_{t-1}, x_t]+b_o) $$
	C的更新值：$$ \check{C}_t =\tanh(W_C[h_{t-1}, x_t]+b_C) $$
	更新C：$$ C_t= f_t*C_{t-1}+i_t*\check{C}_t $$
	输出h：$$ h_t=o_t*\tanh(C_t) $$

> LSTM与GRU
> 将遗忘门和输入门合并为更新门z，并新增重置门r。
> ![GRU](img\GRU.webp)
> 两者在性能上差别不大，GRU参数更少，更容易收敛，但在大数据的境况下，LSTM效果更好。两个在更新记忆细胞C的时候，都用到了加法，可以防止梯度弥散，因此都比常规的RNN效果好。

---
- **HMM的三种问题与解法**
    **HMM有三个要素：可见状态、隐含状态、状态转移矩阵；**
    1. 根据可见状态、状态转移矩阵和隐含状态数量，求隐含状态链，(词性标注)。**使用Viterbi算法**。
    2. 根据可见状态、状态转移矩阵、隐含状态，求出现这个结果的概率。**前向算法**
    3. 根据可见状态、可见状态、隐含状态，求解状态转移矩阵。...
---
- **MySql索引**
可以分为普通索引(可以不唯一)和唯一索引，索引的目的是提升查询速度，但是会降低修改表的速度(增、删、改)，因此应该在合理的场景下设置索引。

- **MySQL引擎**

数据库引擎的作用：设计并创建数据库以保存系统所需的关系或XML文档；实现系统以访问和更改数据库中存储的数据；为单位或客户部署实现的系统；提供日常管理支持以优化数据库的性能。

主要的引擎有: 1. MyIsam , 2. InnoDB, 3. Memory, 4. Blackhole, 5. CSV, 6. Performance_Schema, 7. Archive, 8. Federated , 9 Mrg_Myisam

InnoDB的特点：
1. 具有提交、回滚和崩溃恢复能力的事务安全(ACID兼容)存储引擎；
2. 锁定在行级，并且SELECT的时候是非锁定读；
3. 支持外键约束；
4. 为了处理巨大量数据的最大性能设计；

事务(ACID)的四个特性：
1. 原子性：要么全执行要么不执行；
2. 一致性：事务不会改变数据库中数据的一致性；
3. 独立性：各个事务之间互相独立，不会交错执行；
4. 持久性：对数据库的操作是持久性的直接保存。 

InnoDB与MyISAM的对比：
1. MyISAM不支持事务，也不支持外键索引；
2. MyISAM性能更好，操作更快；
3. MyISAM会保存行数，InnoDB不会，SELECT COUNT(*) FROM TABLE时会扫面全表；
4. MyISAM支持全文索引、压缩索引，InnoDB不支持。使用自增字段时，InnoDB中必须使用只有该字段的索引，MyISAM中可以和其他字段建立联合索引；
5. InnoDB支持行锁，MyISAM只支持表锁；

---
- **特征选择的算法**
	关于特征工程的[知乎链接](https://www.zhihu.com/question/28641663)。
	从两个方面考虑：特征是否发散——如果特征不发散，例如方差接近于0，也就是说样本在这个特征上基本没有差异，那么这个特征对于样本的区分没有什么区别；特征与目标的相关性——与目标相关性高的特征，应当优先选择。
	
	1. 过滤法(Filter)
		* 方差选择法，先计算方差，然后确定阈值，低于阈值的去掉；
		* 相关系数法，先计算各个特征对目标值的相关系数以及相关系数的P值；
		* 卡方检验，检验定性自变量与定性因变量之间的相关性；
		* 互信息法，最大信息系数。
		> ~~~python
		> # 方差选择法
		> from sklearn.feature_selection import VarianceThreshold
		> # threshold即阈值
		> VarianceThreshold(threshold=3).fit_transform(iris.data)
		> 
		> # 相关系数法
		> from sklearn.feature_selection import SelectKBest
		> from scipy.stats import pearsonr
		> SelectKBest(lambda X, Y: array(map(lambda x:pearsonr(x, Y), X.T)).T, k=2).fit_transform(iris.data, iris.target)
		> 
		> # 卡方检验
		> from sklearn.feature_selection import chi2
		> # 选取k个特征
		> SelectKBest(chi2, k=2).fit_transform(iris.data, iris.target)
		> 
		> # 互信息法
		> from minepy import MINE
		> def mic(x, y):
		>     m = MINE()
		>     m.compute_score(x, y)
		>     return (m.mic(), 0.5)
		> SelectKBest(lambda X, Y: array(map(lambda x:mic(x, Y), X.T)).T, k=2).fit_transform(iris.data, iris.target)
		> ~~~
		
	2. 包装法(Wrapper)
		* 递归特征消除法，使用一个基模型进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。
		> ~~~python
		> from sklearn.feature_selection import RFE
		> from sklearn.linear_model import LogisticRegression
		> 
		> # estimator为基模型
		> # n_features_to_select为选择的特征数量
		> RFE(estimator=LogisticRegression(), n_features_to_select=2).fit_transform(iris.data, iris.target)
		> ~~~

	3. 嵌入法(Embedded)
		* 基于惩罚项的特征选择法。使用带惩罚项的基模型，除了筛选特征之外，同时进行降维。可以使用`l1`、`l2`以及两个惩罚项的结合。
		* 基于树模型的特征选择法
		> ~~~python
		> from sklearn.feature_selection import SelectFromModel
		> from sklearn.linear_model import LogisticRegression
		> # penalty惩罚项
		> # 使用l1 + l2混合惩罚项，需要重写LR，详见知乎链接
		> SelectFromModel(LogisticRegression(penalty="l1", C=0.1)).fit_transform(iris.data, iris.target)
		> 
		> from sklearn.ensemble import GradientBoostingClassifier
		> # 使用GBDT进行特征选择
		> SelectFromModel(GradientBoostingClassifier()).fit_transform(iris.data, iris.target)
		> ~~~

***特征工程结构***
![特征工程](img\特征工程.jpg)

---
- **极大似然估计**

从抛硬币开始：一枚硬币，抛了10次，正面6次，反面4次，用极大似然的方法计算出现证明的概率。
	1. 由题干可知，$P(10次出现6次正面)=p^6*(1-p)^4$。极大似然估计的核心就是，让$P(10次出现6次正面)$的概率最大。
	2. 构造似然函数$L(p)=p^6*(1-p)^4$最大，即求得一阶导数$L'(p)=0$时，p的值就是抛硬币出现正面的概率。
	3. 指数难以计算，因此使用对数似然$l(p)=\log(L(p))=6\log(p)+4\log(1-p)$。
	4. 求一阶导数为：$l'(p)=\frac{6}{p}-\frac{4}{1-p}$
	5. 令$l'(p)=0$，求得$p=0.6$，则正面朝上的概率为0.6

那么，从抛硬币推广到逻辑回归。逻辑回归的思想也是通过0-1分布实现样本的分类。
逻辑回归的函数为：
$$
f(x)=\frac{1}{1+e^{g(x)}}
$$
$$
g(x)=\theta * x
$$
得到概率分布：
$$
p(y|x;\theta)=\begin{cases}
h_\theta(x) & y=1\\
1-h_\theta(x) & y=0
\end{cases}
$$
对于多个特征，即多个x，似然函数$L(\theta)$：
$$
L(\theta)=\prod_{i=1}^m(h_\theta(x^{(i)}))^{y^{(i)}}*(1-h_\theta(x^{(i)}))^{1-y^{(i)}}
$$
对数似然函数为：
$$
l(\theta)=\log(L(\theta))=\sum_{i=1}^{m}[y^{(i)}\log(h_{\theta}(x^{(i)})+(1-y^{(i)})\log(1-h_{\theta}(x^{(i)}))]
$$
梯度下降，求最小值：
$$
J(\theta)=-\frac{1}{m}l(\theta)
$$
求导之后：
$$
\frac{\partial J(\theta)}{\partial \theta_j} = \frac{1}{m}\sum_{i=1}^{m}[(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}]
$$
则，梯度下降，参数更新：
$$
\theta :=\theta-\alpha\frac{1}{m}\sum_{i=1}^{m}[(h_\theta(x^{(i)})-y^{(i)})x^{(i)}]
$$

---
- **XGBoost的节点分裂**
	* AdaBoost：[原理与推导](https://www.cnblogs.com/ScorpioLu/p/8295990.html)
	* GBDT:
	* XGBoost:

---
- **VIF的原理**



### LightGBM与XGBoost的区别。

1. 树的成长方式，LGB是leaf-wise，xgb是level-wise；
2. 直方图算法，将连续变量变成离散变量，按照bin分箱，降低复杂度，相当于正则化；
3. lgb还支持分类变量，xgb处理分类变量，需要先one-hot编码，然后处理，数据稀疏造成效果不好；
4. LGB还支持特征合并，按照冲突最少的策略，将两个特征合并；
5. 并行的处理方式，LGB支持数据并行和特征并行，xgb只能在特征排序和分裂点选择上能够并行。