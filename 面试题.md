- **深度学习的优化函数**
	1. **批梯度下降(BGD)**

	    更新规则：每次更新参数时使用全部训练样本；
	    $$ \theta = \theta- \eta\frac{\partial J(\theta)}{\partial\theta}$$
	    优点：理想状态下经过足够多的迭代后可以达到全局最优。（对于凸函数可以收敛到全局极小值，对于非凸函数可以收敛到局部最小值）
	    缺点：一次更新就要对整个数据集计算梯度，所以计算非常慢。
	
	2. **随机梯度下降(SGD)**
	    优化方式：每次更新参数时随机选用一个样本。
	    $$ \theta = \theta- \eta\frac{\partial J(\theta;x^{(i)};y^{(i)})}{\partial\theta} $$
	    优点：相比于BGD，训练速度更快，更快收敛。
	    缺点：随机梯度下降会带来一定的问题，因为计算得到的并不是准确的一个梯度，SGD 的噪音较 BGD 要多，使得 SGD 并不是每次迭代都向着整体最优化方向。 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近。SGD 因为更新比较频繁，会造成 cost function 有严重的震荡。BGD 可以收敛到局部极小值，当然 SGD 的震荡可能会跳到更好的局部极小值处。当我们稍微减小 learning rate，SGD 和 BGD 的收敛性是一样的。
	    
	3. **小批次梯度下降(MBGD)**   
	    优化方式：每次更新参数时利用一小批样本。
	    $$ \theta = \theta- \eta\frac{\partial J(\theta;x^{(i;i+n)};y^{(i;i+n)})}{\partial\theta} $$
	    优点：相较于BGD更快，相较于SGD更稳定
	    缺点：当我们采用小的学习率的时候，会导致网络在训练的时候收敛太慢；当我们采用大的学习率的时候，会导致在训练过程中优化的幅度跳过函数的范围，也就是可能跳过最优点。对于非凸函数，还要避免陷于局部极小值处，或者鞍点处。
	    
	4. **Momentum**
	    优化方式：在梯度下降的方向上计算一个指数加权平均，利用这个来代替权重更新。俗一点的理解就是“如果梯度下降显示，我们在一直朝着某一个方向在下降的话，我让这个方向的的学习速率快一点，如果梯度下降在某一个方向上一直是摆来摆去的，那么就让这个方向的学习速率慢一点”。
	    $$ v_t=\lambda v_{t-1}+\eta\frac{\partial J(\theta)}{\partial\theta} $$
	    $$ \theta = \theta-v_t $$
	    优点：加速了横轴下降的速度，并减缓了纵轴的摆动频率。
	    
	5. **AdaGrad**
	    优化方式：根据自变量在每个维度的梯度值的大小来调整各位维度上的学习率，从而避免统一的学习率难以适应所有维度的问题。
	    $$g_{t,i}=\frac{\partial J(\theta_{t,i})}{\partial\theta}$$
	    $$ \theta_{t+1,i}=\theta_{t,i}-\frac{\eta}{\sqrt{G_{t,i}+\varepsilon}}g_{t,i} $$
	    其中G是一个对角矩阵，对角线元素是截止到当前时刻的历史梯度的平方和。
	    优点：适合于特征稀疏的场景。不需要手动设置学习率。
	    缺点：其分母梯度平方的累加和。因为每次加入的都是一个正数，随着训练的进行，学习率将会变得无限小，此时算法将不能进行参数的迭代更新

	6. **RMSProp**
	    优化方式：RMSProp 基于 AdaGrad，进行了一些小小的改动，也解决了我们上面提出来的，在随着训练时间增长，AdaGrad 的步伐会变得很小的问题。RMSProp 在计算 grad_squared 的时候，加上了一个 decay （衰减率）的东西，这样造成的效果即是，既保留了 AdaGrad 的特性，又不会一直过分增加 grad_squared 导致最后阻力过大。
	    $$ E[g^2] _t=0.9E[g^2]_{t-1}+0.1g_t^2$$
	    $$ \theta_{t+1}=\theta_t-\frac{\eta}{\sqrt{E[g^2]_t+\varepsilon}}g_t $$
	    
	7. **Adam(Adaptive Moment Estimation)**
	    Adam相当于RMSProp+Momentum，即存储了过去梯度的平方的指数衰减平均值,也保存了过去梯度的指数衰减平均值,通过校正的一阶矩(均值)和二阶矩(方差)估计来抵消误差。
	    $$ m_t=\beta_1m_{t-1}+(1-\beta_1)g_t $$
	    $$ v_t=\beta_2v_{t-1}+(1-\beta_1)g_t^2 $$
	    $$ \hat{m}_t=\frac{m_t}{1-\beta_1^t} $$
	    $$ \hat{v}_t=\frac{v_t}{1-\beta_2^t} $$
	    $$ \theta_{t+1}=\theta_t-\frac{\eta}{\sqrt{\hat{v}_t}+\varepsilon}\hat{m}_t $$
	    实践证明,Adam相比于其他适应性学习方法效果要好.
	    建议$\beta_1=0.9,\beta_2=0.999,\varepsilon=10e-8$

---

- **深度学习的损失函数**

	**分类**
	
	1.  Sigmoid_cross_entropy
	    测量每个类别独立且不互相排斥的离散分类人中的概率，可以执行多标签分类。
	    $$ L(y,\hat{y}) = -\frac{1}{2}*(\hat{y}*log(sigmoid(y))+(1-\hat{y})*log(1-sigmoid(y)))  $$
	    
	    ```python
	    # keras 的接口：
	    binary_crossentropy(y_true,y_pred)
	    ```
	    > 对于softmax_cross_entropy, sigmoid_cross_entropy之间的区别：
	    > softmax_cross_entropy是多分类问题，有多个类别，且互斥；激活函数使用softmax，keras的损失函数使用`categorical cross-entropy`
	    > sigmoid_cross_entropy是多目标分类问题，有多个类别，但类别之间互相独立，可以转换成多个二分类问题解决。激活函数使用sigmoid，keras的损失函数使用`binary cross-entropy`
	    
	2. balanced_sigmoid_cross_entropy
	    相较于sigmoid_cross_entropy的优势在于加入平衡参数，可以进行正负样本的平衡。
	    $$ L(y,\hat{y}) = -\frac{1}{2}*(\beta\hat{y}*log(sigmoid(y))+(1-\beta)(1-\hat{y})*log(1-sigmoid(y))) $$
	
	3. Focal Loss
      通过不同类别的分类概率$p_t$，概率越大，权重越小，也就实现了对easy example的权重进行抑制；
      $$FL(p_t)=-\alpha_t(1-p_t)^\gamma log(p_t)$$
      当时反例时，使用$1-\alpha$代替$\alpha$
      ```python
        def focal_loss(logits, labels, gamma):
        '''
        :param logits:  [batch_size, n_class]
        :param labels: [batch_size]
        :return: -(1-y)^r * log(y)
        '''
        	softmax = tf.reshape(tf.nn.softmax(logits), [-1])  # [batch_size * n_class]
        	labels = tf.range(0, logits.shape[0]) * logits.shape[1] + labels
	      	prob = tf.gather(softmax, labels)
	      	weight = tf.pow(tf.subtract(1., prob), gamma)
	      	loss = -tf.reduce_mean(tf.multiply(weight, tf.log(prob)))
	      	return loss  
	    ```
	
	4. hinge_loss
	    也叫铰链损失，是SVM中的损失函数。合页损失优化到满足小于一定gap距离就会停止优化，所以，通常情况下，交叉熵损失效果优于合页损失。
	    $$ L(y,\hat{y}=\frac{1}{n}\sum_{i=1}{n}max(0,1-\hat{y}*y_i)) $$
	
	**回归**
	
		1. MSE(均方误差)
	
	 	2. MAE(平均绝对误差)
	 	3. MAPE(平均绝对百分比误差)
	 	4. MSLE(均方对数误差)

---
- **深度学习的激活函数**
	1.Sigmoid
	    公式：$ f(x)=\frac{1}{1+e^{-x}} $
	    取值范围:[0;1]
	    ![sigmoid](D:\workspace\Python\leetcode\img\sigmoid.png)
	    缺点：两端梯度消失;输出不是"零为中心"；指数计算复杂度高。
	2.tanh
	    公式：$tanh(x)=2sigmoid(2x)-1=\frac{1-e^{-2x}}{1+e^{-2x}}$
	    取值范围:[-1;1]
- ![tanh](D:\workspace\Python\leetcode\img\tanh.png)
	    缺点：两端梯度消失；指数计算复杂度高。
	3.ReLU
	    公式：$ ReLU(x)=max(0, x) $
	    取值范围：>=0
	    ![ReLU](D:\workspace\Python\leetcode\img\ReLU.png)
	    优点：解决了在x>0时的梯度消失问题；在SGD中能够快速收敛；线性关系，计算复杂度低；
	    缺点：不是"零为中心"；随着训练进行，可能出现神经元不可逆转的死亡；
	4.Leaky ReLU
	    公式：$ f(x)=\begin{cases}  x & x>=0 \\ \alpha x & x<0 \end{cases} $
	    优点：神经元不会死亡；也不会梯度消失；能够快速收敛；计算速度快；
	    缺点：$\alpha$需要先验知识。
	5.RReLU
	    Leaky ReLU的$\alpha$服从一个分布，会在训练中随机产生并进行修正，在测试环节计算平均值。
	6.ELU
	    公式：$f(x)=\begin{cases} x&x>0 \\ \alpha(e^x-1) & x<=0 \end{cases}$
	    ![img](https://img-blog.csdn.net/20160917160040231)
	    优点：ReLU的所有优点，不会死亡，输出均值接近于0；
	    缺点：指数运算，效率相对较低。
	7.Maxout
	    公式：$ f(x)= \max(w_1^Tx+b_1, w_2^Tx+b_2,...,w_k^Tx+b_k) $
	    优点：因为ReLU是Maxout的特殊化，所以有ReLU的所有优点，且不会死亡；
	    缺点：参数较多，原本一组参数，因为编成k组，导致参数变多。
---
- **LSTM**
	输入：$C_{t-1}, h_{t-1}, x_t$
	输出：$C_t, h_t$
	![LSTM](D:\workspace\Python\leetcode\img\LSTM.jpg)
	遗忘门：$$ f_t =\sigma(W_f[h_{t-1}, x_t]+b_f) $$
	输入门：$$ i_t =\sigma(W_i[h_{t-1}, x_t]+b_i) $$
	输出门：$$ o_t = \sigma(W_o[h_{t-1}, x_t]+b_o) $$
	C的更新值：$$ \check{C}_t =\tanh(W_C[h_{t-1}, x_t]+b_C) $$
	更新C：$$ C_t= f_t*C_{t-1}+i_t*\check{C}_t $$
	输出h：$$ h_t=o_t*\tanh(C_t) $$

> LSTM与GRU
> 将遗忘门和输入门合并为更新门z，并新增重置门r。
> ![GRU](D:\workspace\Python\leetcode\img\GRU.webp)
> 两者在性能上差别不大，GRU参数更少，更容易收敛，但在大数据的境况下，LSTM效果更好。两个在更新记忆细胞C的时候，都用到了加法，可以防止梯度弥散，因此都比常规的RNN效果好。

---
- HMM的三种问题与解法
    **HMM有三个要素：可见状态、隐含状态、状态转移矩阵；**
    1. 根据可见状态、状态转移矩阵和隐含状态数量，求隐含状态链，(词性标注)。**使用Viterbi算法**。
    2. 根据可见状态、状态转移矩阵、隐含状态，求出现这个结果的概率。**前向算法**
    3. 根据可见状态、可见状态、隐含状态，求解状态转移矩阵。...

- TODO