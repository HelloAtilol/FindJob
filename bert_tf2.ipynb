{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据加载完成...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import *\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 构建训练集和测试集\n",
    "EPOCH = 1000\n",
    "BATCH_SIZE = 32\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "BATH_PATH = \"/home/wangchengkun/workspace/wechat_bert/\"\n",
    "origin_data = pd.read_csv(BATH_PATH + \"data/social_support_new.csv\", )\n",
    "origin_data = np.array(origin_data)\n",
    "\n",
    "# 处理x值，在这一步直接tokenizer\n",
    "x_all = x_train = []\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "for x in list(origin_data[:, 3]):\n",
    "    x_all.append(tokenizer.encode(str(x), add_special_tokens=True, \n",
    "                 max_length=MAX_LENGTH, pad_to_max_length='right'))\n",
    "# 处理y值\n",
    "y_all = origin_data[:, 4]\n",
    "\n",
    "# 划分x_train, x_test, y_train, y_test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, random_state=42, \n",
    "                                                    test_size=0.05)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, list(y_train)))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, list(y_test)))\n",
    "print(\"数据加载完成...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_predict = np.argmax(val_predict, axis=1)\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict)\n",
    "        _val_recall = recall_score(val_targ, val_predict)\n",
    "        _val_precision = precision_score(val_targ, val_predict)\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print(\"\\n— val_f1: %f — val_precision: %f — val_recall %f\" %(_val_f1, _val_precision, _val_recall))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型构建完成...\n",
      "Epoch 1/1000\n",
      "    402/Unknown - 151s 375ms/step - loss: 3.0994 - accuracy: 0.7989\n",
      "— val_f1: 0.000000 — val_precision: 0.000000 — val_recall 0.000000\n",
      "402/402 [==============================] - 157s 390ms/step - loss: 3.0994 - accuracy: 0.7989 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "401/402 [============================>.] - ETA: 0s - loss: 3.1013 - accuracy: 0.7989\n",
      "— val_f1: 0.000000 — val_precision: 0.000000 — val_recall 0.000000\n",
      "402/402 [==============================] - 145s 362ms/step - loss: 3.1013 - accuracy: 0.7990 - val_loss: 2.4101 - val_accuracy: 0.8438\n",
      "Epoch 3/1000\n",
      "401/402 [============================>.] - ETA: 0s - loss: 3.1013 - accuracy: 0.7989\n",
      "— val_f1: 0.000000 — val_precision: 0.000000 — val_recall 0.000000\n",
      "402/402 [==============================] - 146s 363ms/step - loss: 3.1013 - accuracy: 0.7990 - val_loss: 2.4101 - val_accuracy: 0.8438\n",
      "Epoch 4/1000\n",
      "401/402 [============================>.] - ETA: 0s - loss: 3.1013 - accuracy: 0.7989\n",
      "— val_f1: 0.000000 — val_precision: 0.000000 — val_recall 0.000000\n",
      "402/402 [==============================] - 146s 363ms/step - loss: 3.1013 - accuracy: 0.7990 - val_loss: 2.4101 - val_accuracy: 0.8438\n",
      "Epoch 5/1000\n",
      "401/402 [============================>.] - ETA: 0s - loss: 3.1013 - accuracy: 0.7989\n",
      "— val_f1: 0.000000 — val_precision: 0.000000 — val_recall 0.000000\n",
      "402/402 [==============================] - 146s 363ms/step - loss: 3.1013 - accuracy: 0.7990 - val_loss: 2.4101 - val_accuracy: 0.8438\n",
      "Epoch 6/1000\n",
      "401/402 [============================>.] - ETA: 0s - loss: 3.1013 - accuracy: 0.7989\n",
      "— val_f1: 0.000000 — val_precision: 0.000000 — val_recall 0.000000\n",
      "402/402 [==============================] - 146s 364ms/step - loss: 3.1013 - accuracy: 0.7990 - val_loss: 2.4101 - val_accuracy: 0.8438\n",
      "Epoch 7/1000\n",
      "401/402 [============================>.] - ETA: 0s - loss: 3.1013 - accuracy: 0.7989\n",
      "— val_f1: 0.000000 — val_precision: 0.000000 — val_recall 0.000000\n",
      "402/402 [==============================] - 146s 363ms/step - loss: 3.1013 - accuracy: 0.7990 - val_loss: 2.4101 - val_accuracy: 0.8438\n",
      "Epoch 8/1000\n",
      "401/402 [============================>.] - ETA: 0s - loss: 3.0877 - accuracy: 0.7910\n",
      "— val_f1: 0.311721 — val_precision: 0.184638 — val_recall 1.000000\n",
      "402/402 [==============================] - 146s 364ms/step - loss: 3.0877 - accuracy: 0.7910 - val_loss: 2.4161 - val_accuracy: 0.8430\n",
      "Epoch 9/1000\n",
      "401/402 [============================>.] - ETA: 0s - loss: 3.1013 - accuracy: 0.7989\n",
      "— val_f1: 0.311721 — val_precision: 0.184638 — val_recall 1.000000\n",
      "402/402 [==============================] - 146s 362ms/step - loss: 3.1013 - accuracy: 0.7990 - val_loss: 2.4738 - val_accuracy: 0.8396\n",
      "Epoch 10/1000\n",
      "401/402 [============================>.] - ETA: 0s - loss: 3.1013 - accuracy: 0.7989\n",
      "— val_f1: 0.311721 — val_precision: 0.184638 — val_recall 1.000000\n",
      "402/402 [==============================] - 146s 363ms/step - loss: 3.1013 - accuracy: 0.7990 - val_loss: 2.4738 - val_accuracy: 0.8396\n",
      "Epoch 11/1000\n",
      "401/402 [============================>.] - ETA: 0s - loss: 3.1013 - accuracy: 0.7989\n",
      "— val_f1: 0.311721 — val_precision: 0.184638 — val_recall 1.000000\n",
      "402/402 [==============================] - 146s 362ms/step - loss: 3.1013 - accuracy: 0.7990 - val_loss: 2.4738 - val_accuracy: 0.8396\n",
      "Epoch 12/1000\n",
      "275/402 [===================>..........] - ETA: 45s - loss: 3.1674 - accuracy: 0.7947"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-chinese\")\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer = tf.keras.optimizers.Adam(1e-4),\n",
    "             metrics=[\"accuracy\"])\n",
    "# 构建F1值计算工具\n",
    "metrics = Metrics()\n",
    "metrics.validation_data = (x_test, list(y_test))\n",
    "print(\"模型构建完成...\")\n",
    "history = model.fit(train_dataset, epochs=EPOCH,\n",
    "                    callbacks=[metrics],\n",
    "                   validation_data=test_dataset,\n",
    "                   validation_steps=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
